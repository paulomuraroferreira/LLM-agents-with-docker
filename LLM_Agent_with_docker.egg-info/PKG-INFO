Metadata-Version: 2.1
Name: LLM-Agent-with-docker
Version: 0.1.0
Summary: This project implements a Postgres Agent that runs code in a docker container.
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: aiohappyeyeballs==2.4.0
Requires-Dist: aiohttp==3.10.5
Requires-Dist: aiosignal==1.3.1
Requires-Dist: aiosqlite==0.20.0
Requires-Dist: annotated-types==0.7.0
Requires-Dist: anyio==4.4.0
Requires-Dist: attrs==24.2.0
Requires-Dist: certifi==2024.7.4
Requires-Dist: charset-normalizer==3.3.2
Requires-Dist: contourpy==1.2.1
Requires-Dist: cycler==0.12.1
Requires-Dist: dataclasses-json==0.6.7
Requires-Dist: distro==1.9.0
Requires-Dist: docker==7.1.0
Requires-Dist: fonttools==4.53.1
Requires-Dist: frozenlist==1.4.1
Requires-Dist: greenlet==3.0.3
Requires-Dist: h11==0.14.0
Requires-Dist: httpcore==1.0.5
Requires-Dist: httpx==0.27.0
Requires-Dist: idna==3.8
Requires-Dist: jiter==0.5.0
Requires-Dist: jsonpatch==1.33
Requires-Dist: jsonpointer==3.0.0
Requires-Dist: kiwisolver==1.4.5
Requires-Dist: langchain==0.2.14
Requires-Dist: langchain-community==0.2.12
Requires-Dist: langchain-core==0.2.34
Requires-Dist: langchain-openai==0.1.22
Requires-Dist: langchain-text-splitters==0.2.2
Requires-Dist: langgraph==0.2.14
Requires-Dist: langgraph-checkpoint==1.0.6
Requires-Dist: langgraph-checkpoint-sqlite==1.0.0
Requires-Dist: langsmith==0.1.104
Requires-Dist: marshmallow==3.22.0
Requires-Dist: matplotlib==3.9.2
Requires-Dist: multidict==6.0.5
Requires-Dist: mypy-extensions==1.0.0
Requires-Dist: numpy==1.26.4
Requires-Dist: openai==1.42.0
Requires-Dist: orjson==3.10.7
Requires-Dist: packaging==24.1
Requires-Dist: pandas==2.2.2
Requires-Dist: pillow==10.4.0
Requires-Dist: psycopg2==2.9.9
Requires-Dist: pydantic==2.8.2
Requires-Dist: pydantic_core==2.20.1
Requires-Dist: pyparsing==3.1.2
Requires-Dist: python-dateutil==2.9.0.post0
Requires-Dist: python-dotenv==1.0.1
Requires-Dist: pytz==2024.1
Requires-Dist: PyYAML==6.0.2
Requires-Dist: regex==2024.7.24
Requires-Dist: requests==2.32.3
Requires-Dist: six==1.16.0
Requires-Dist: sniffio==1.3.1
Requires-Dist: SQLAlchemy==2.0.32
Requires-Dist: tenacity==8.5.0
Requires-Dist: tiktoken==0.7.0
Requires-Dist: tqdm==4.66.5
Requires-Dist: typing-inspect==0.9.0
Requires-Dist: typing_extensions==4.12.2
Requires-Dist: tzdata==2024.1
Requires-Dist: urllib3==2.2.2
Requires-Dist: yarl==1.9.4
Provides-Extra: dev
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Provides-Extra: test
Requires-Dist: pytest; extra == "test"
Requires-Dist: pytest-cov; extra == "test"

# README

WATCH THE DEMO: https://www.youtube.com/watch?v=uGqmn2xdU54

This repository is based on the code from LangChain's Azure Container Apps Dynamic Sessions Data Analyst Notebook (https://github.com/langchain-ai/langchain/blob/master/cookbook/azure_container_apps_dynamic_sessions_data_analyst.ipynb), where an agent reads data from a PostgreSQL database, saves it in a CSV file, and executes code based on the CSV file, such as plotting a graph.

The main feature of the code was that it executed code in a container using Azure Container Apps dynamic sessions.

This project replaces the Azure Container Apps dynamic sessions with docker. So when the agent executes the code, it will create a docker container, execute the code, and then remove the container. This ensures that the host machine is safe from arbitrary code from the agent.

The agent architecture is as follows:

![image.png](README_files/image.png)

After the execute_sql_query node is executed, the data is saved as a CSV on the host machine. The Docker container then has read-only permission to access this CSV. If it plots anything, the image is passed back to the host machine via a Base64 string.


## Setup Instructions

1. Clone the repository:


```python
git clone https://github.com/paulomuraroferreira/LLM-agents-with-docker.git
cd LLM-agents-with-docker
```

2. Install Dependencies:

```python
$pip install -e .
```

Also, ensure you have Docker installed and running.

3. Environment Configuration:

Create a .env file and fill the following environment variables:

```python
OPENAI_API_KEY=your_openai_api_key
DATABASE_URL=your_postgres_url
LLM_MODEL=i am using 'gpt-4o'
```

4. Run the Application:

Execute the main script to initialize the workflow and handle user queries:

```python
python main.py
```
